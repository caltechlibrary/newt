<!DOCTYPE html>
<html>
<head>
    <title>Newt -- a new take on the webstack</title>
    <link rel="stylesheet" href="https://caltechlibrary.github.io/css/site.css">
</head>
<body>
<header>
<a href="https://library.caltech.edu"><img src="https://caltechlibrary.github.io/assets/liblogo.gif" alt="Caltech Library logo"></a>
</header>
<nav>
<ul>
	<li><a href="/">Home</a></li>
	<li><a href="./">README</a></li>
	<li><a href="user_manual.html">User Manual</a></li>
	<li><a href="LICENSE">LICENSE</a></li>
	<li><a href="INSTALL.html">INSTALL</a></li>
	<li><a href="about.html">About</a></li>
	<li><a href="https://github.com/caltechlibrary/newt">GitHub</a></li>
</ul>
</nav>

<section>
<h1 id="newt-project">Newt Project</h1>
<p>The Newt Project is an experiment in rapid web application
development for libraries, archives and museums (a.k.a.
<abbr title="libraries, archives and museums abbrevation">LAS</abbr>).
Newt uses a service oriented architecture forming data pipelines<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>. The pipelines compose the web
application.</p>
<p>Taking this approach minimizes the software you need to write in
favor of configuration. This is because “off the shelf” software is
available to do the heavy lifting. Example, Postgres+PostgREST gives you
an out of the box, web friendly, data management platform in the form of
a JSON API. Light weight template engines like Pandoc running as a web
service can transform you JSON API output into a web page. Throw in a
full text search engine like Solr and you can check off the core
features of many LAS software systems. What is missing is the layer to
orchestrate the data flowing through a pipe.</p>
<p>The Newt Project is trying to encourage the following
characteristics.</p>
<ul>
<li>preference for “off the shelf” over writing new code</li>
<li>data modeling and management placed squarely in your database
management system</li>
<li>data sources accessed as JSON API</li>
<li>data transformation (if needed) happens in simple stateless template
engines</li>
<li>leverage code generation when appropriate</li>
</ul>
<p>The Newt Project is exploring this by providing three tools to fill
in the gaps.</p>
<ul>
<li><code>newt</code> is a stateless web service (a.k.a. micro service)
that routes a web request through a data pipe line built from other web
services</li>
<li><code>newtgen</code> is a code generator that can take a set of data
models described in YAML and generate SQL, HTML and templates based on
those models</li>
<li><code>newtmustache</code> is a simple stateless template engine
inspired by Pandoc server that supports the Mustache template
language</li>
</ul>
<p>The Newt web services and data pipeline concept is being tested
using</p>
<ul>
<li><a href="https://postgres.org">Postgres</a>, data management and
modeling</li>
<li><a href="https://postgrest.org">PostgREST</a>, a service that turns
Postgres into a JSON API</li>
<li><a href="https://solr.apache.org">Solr</a>, full text search that
provides a JSON API</li>
</ul>
<p>Newt can tie these together through YAML expressing</p>
<ul>
<li>application definition (run time information and application
metadata)</li>
<li>routes (web requests differentiated by a HTTP method, headers and
URL path)</li>
<li>models (describe the data as would be input into a web form)</li>
</ul>
<h2 id="what-type-of-applications-are-supported-by-newt">What type of
applications are supported by Newt?</h2>
<p>Most LAS applications are focused on managing and curating some sort
of metadata record. This is the primary target of Newt. This might be as
simple as a controlled vocabulary or as complex as a archival or
repository metadata record.</p>
<h2 id="motivation">Motivation</h2>
<p>Over the last several decade web applications become very complex.
This complexity is expensive in terms of reliability, enhancement, big
fixes and software sustainability.</p>
<blockquote>
<p>A brief historic detour to set context</p>
</blockquote>
<p>Databases have been used to generate web pages since the early web.
Databases are well suited to managing data. When the web became dynamic,
databases continued to be use for data persistence. The web as an
application was born and proceeded to eat all the venerable green screen
systems to could find. When that was complete it continued to engorge
itself until we have the web today and along with a problematic
surveillance economy. Somewhere in that time frame became a good
platform for providing useful organizational software.</p>
<p>In the 1990s the Open Source databases of choice were MySQL and
Postgres. Neither MySQL or Postgres spoke HTTP (the protocol the web
runs on). To solve this problem many people wrote software in languages
like Perl, PHP and Python that ran inside the popular web server
software called Apache. It was a pain to setup but once setup relatively
easy to build things that relied on databases. This led the web to
explode with bespoke systems for curating and distributing web content.
By the late 1990s and the early 2000s the practice of “mashing up” sites
(i.e. content reuse) became the rage. As this increased in popularity
web systems specialized further to cater to reuse. <a
href="https://en.wikipedia.org/wiki/Yahoo!_Pipes">Yahoo Pipes</a> was a
very interesting expression of the “mashup culture”. The basic concept
was to “data feeds” and combined them into a useful human friendly web
pages. Specialization has continued. Some of these systems have become
less bespoke. Eventual the useful concept between software that could be
used “off the shelf”. A good example is Apache’s <a
href="https://solr.apache.org">Solr</a> search engine.</p>
<p>Fast forward to 2024. The back end of web applications can largely be
assemble from off the shelf software. While middleware has grown large
and complex that can be viewed as a by product of inertia and the
assumption that what is good for “Google Scale” is good for
everyone.</p>
<p>I think a radical simplification is due. Most software doesn’t need
to scale that large. Even in the research and LAS communities we don’t
routinely write software that scales as large as Zenodo. We just to
typically see tens of thousands of simultaneous users. If that premise
is acceptable then we can focus our efforts around orchestrating off the
shelf components and put most of our efforts into improving the human
experience of using our software.</p>
<p>A big key to simplification is realizing that the middleware no
longer needs to be responsible for managing data models, access and
users, data transformation and doesn’t even need need to be completely
bespoke. If you can configure the data routes and your data models the
rest could become turn key.</p>
<h2 id="off-the-shelf-delivers">Off the shelf delivers</h2>
<ul>
<li>Postgres combined with PostgREST gives you an out of the box JSON
API for managing data</li>
<li>Solr gives you a powerful, friendly, JSON API for search and
discovery</li>
<li>Pandoc running as a web service provides a simple but powerful
template engine</li>
<li>Apache 2 or NginX when combined with a single sign on system
(e.g. Shibboleth) provides access control</li>
<li>Web browsers now provide a rich software platform in their own
right</li>
</ul>
<h2 id="this-missing-bits">This missing bits</h2>
<p>With the above list along you can build complex applications that run
inside the web browser and never move beyond that for the back end aside
from configuration and loading your database schema, views and
functions. The trouble is relying on JavaScript assemble of content in
the web browser is not a nice user experience<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.
It’s nicer if the web browser can make a minimum number of requests to a
single web service and get back useful results without having to process
more than HTML and CSS.</p>
<p>Typically the answer has been to write more middleware and I want to
avoid that complexity.</p>
<p>Over the last many years many web frameworks developed for Go, Java,
JavaScript, PHP, Python, Ruby, etc. rely on a concept of “routes” in
defining the behavior of web applications. A route can be though of as
an HTTP method and a URL path. To build something for the web in these
environments you wind up creating a bunch of functions that map a route
to a data source, assemble it and then hand it back. Sometimes those
functions are well encapsulated (e.g. static file access) requiring
minimal coding. More comply they become complex, setting up data,
validating things, managing data and eventually returning what the web
browser requested.</p>
<p>What if we could treat the output of a data pipeline as easily as we
provide static file access? I think the answer is yes. Newt provides a
simple web service that takes a YAML file and pairs the requests it
receives with a data pipe line. The last stage of the pipeline executed
is returned to the web browser. If there is a failure in the pipe line
then an appropriate error is returned to the requesting web browser.
Additionally Newt’s web service can provide basic data validation by
using its knowledge of the data models available in the pipe line.
Newt’s code generator can create the SQL, templates and HTML to make
that consistent.</p>
<p>With that there isn’t much middleware left to write.</p>
<h2 id="what-comes-with-the-newt-project">What comes with the Newt
Project?</h2>
<ul>
<li><a href="newt.1.html">newt</a> a <a
href="https://en.wikipedia.org/wiki/microservices">web service</a>
designed for working with other “off the shelf” micro services. It
functions both as a data router and as a static file server. It is
responsible for vetting requests against the models described in the
YAML file. The same models used to generate the SQL for the database and
the templates for user with a template engine.</li>
<li><a href="newtgen.1.html">newtgen</a> is a command line program that
reads the Newt YAML file and generates SQL and templates used to build
your application. The SQL generated currently target
Postgres+PostgREST.</li>
<li><a href="newmustache.1.html">newtmustache</a> is a recent additional
to the prototype suite. When discussing using Pandoc templates with
colleagues some people pointed out they didn’t like Pandoc templates.
Newt’s template engine uses <a
href="https://mustache.github.io/">Mustache</a> template markup to
render JSON content. It functions like Pandoc in server mode. You POST a
request to the template engine that includes both your template and JSON
data and it returns the transformed result. This demonstrates that you
can swap out the template engine and still use the Newt web
service.</li>
</ul>
<p>NOTE: See the <a href="user_manual.html">user manual</a> for
details</p>
<h2 id="how-is-newt-speeding-up-development">How is Newt speeding up
development?</h2>
<p>The Newt suite of tools use a common YAML file.</p>
<ol type="1">
<li><code>newtgen</code> can render SQL suitable for bootstrapping your
Postgres+PostgREST database, templates and HTML</li>
<li><code>newtmustache</code> provides a simple, stateless, Mustache
template engine</li>
<li><code>newt</code> provides a data routing</li>
</ol>
<p>This leaves your back end to be constructed from “off the shelf”
parts. Newt allows customization to focus on data models and HTML, CSS
and JavaScript that will run in your web browser.</p>
<h2 id="where-is-development-time-spent">Where is development time
spent?</h2>
<p>The developer writes YAML to generate the back end and the other
services into an application. The developer generates the SQL and
templates needed for the application. They may choose to customize those
further. Newt web service provides the data pipeline management. Once
the back end is configured the developer can focus on the code that runs
in the web browser.</p>
<h2
id="what-about-security-single-sign-on-integration-with-other-websites-or-services">What
about security, single sign-on, integration with other websites or
services?</h2>
<p>The <code>newt</code> program is a simple web service providing data
routing based on its YAML configuration. It’s a team player. In a
production setting it should be used behind a front end web server like
Apache 2 or NginX. That latter can be configured to support single
sign-on systems like Shibboleth<a href="#fn3" class="footnote-ref"
id="fnref3" role="doc-noteref"><sup>3</sup></a>. The front end web
service controls access and handles securing the connection with the web
browser. The front end web service proxies to the Newt web service. Newt
web services runs the data pipeline on localhost. The data pipelines are
off the shelf services like Postgres+PostgREST, Solr and Pandoc server.
Having a clear division of responsibilities helps in securing your web
application. Since Newt only knows how to talk to services on localhost
you can keep it contained and prevent it from being used to doing
nefarious things off system. Similarly if you decide to use Newt’s
template engine, <code>newtmustache</code>, it also is restricted to
localhost. It is stateless and doesn’t use secrets.</p>
<p>Limiting Newt web service applications to localhost keeps them
simple. Only doing the minimum limits the attack surface for those who
want to do mischief. Neither <code>newt</code> or
<code>newtmustache</code> write to disk or require secrets. They only
communicate via localhost using HTTP protocol.</p>
<p>If you need to integrate a Newt application with an external service
(e.g. CrossRef, ORCID or ROR) this can be done browser side or via a
proxy mapped to localhost on your server.</p>
<h3 id="what-about-scaling">What about “scaling”?</h3>
<p><code>newt</code> is just a data router. Aside from its configuration
read at start up it doesn’t maintain state. <code>newtmustache</code>
doesn’t maintain state and the only configuration is the port number it
runs on. Both can safely run with many instances in parallel as needed
on one or more machines. The instances don’t share data or coordinate.
Run waiting for a request and providing an answer. So what does this
mean?</p>
<p>In principle a Newt based application can scale as wide as needed as
long as each element in the pipeline(s) can also scale.</p>
<p>If the elements of your data pipeline can scale then your application
can scale too. In our example Postgres can be configured as a
<abbr title="high availability">HA</abbre> cluster. PostgREST, Pandoc
server, Newt’s mustache engine all are stateless and be run in
parallel.</p>
<p>While my practical use of Newt is targeting the small it should scale
up to meet high volume demands.</p>
<h3 id="anatomy-of-a-newt-based-web-application">Anatomy of a Newt based
web application</h3>
<p>Newt application development is friendly to version control systems
(e.g. Git). It consists of a Newt configuration file, along with
generate SQL files, HTML templates and any static web assets you’ve
added. A typical disk layout of a Newt project could look like this-</p>
<ul>
<li><code>/</code> project folder
<ul>
<li><code>htdocs</code> this directory holds your static content needed
by your web application</li>
<li><code>*.sql</code> these are the SQL files used by your application
to define your models and behaviors in Postgres</li>
<li><code>*.tmpl</code> template files for either Pandoc or Mustache
template engines</li>
<li><code>newt.yaml</code> would hold the a Newt configuration file
(this is an example name for the configuration file, you can name it
whatever you like)</li>
<li><code>CITATION.cff</code> and <code>codemeta.json</code> for project
metadata</li>
</ul></li>
</ul>
<blockquote>
<p>Newt, a type of salamander, doesn’t seek attention. It does its own
thing. You only notice a salamander if you look carefully.</p>
</blockquote>
<h2 id="about-the-newt-source-repository">About the Newt source
repository</h2>
<p>Newt is a project of Caltech Library’s Digital Library Development
group. It is hosted on GitHub at <a
href="https://github.com/caltechlibrary/newt"
class="uri">https://github.com/caltechlibrary/newt</a>. If you have
questions, problems or concerns regarding Newt you can use GitHub issue
tracker to communicate with the development team. It is located at <a
href="https://github.com/caltechlibrary/newt/issues"
class="uri">https://github.com/caltechlibrary/newt/issues</a>.</p>
<h2 id="someday-maybe-exploration">“Someday, maybe” exploration</h2>
<ul>
<li>Integrate S3 protocol to support storing binary or large
objects</li>
</ul>
<h2 id="getting-help">Getting help</h2>
<p><strong>The Newt Project is an experiment!!</strong>. The source code
for the project is supplied “as is”. Newt is most likely broken. At a
stretch it could be considered a working prototype. You should not use
it for production systems. However if you’d like to ask a question or
have something you’d like to contribute please feel free to file a
GitHub issue, see <a
href="https://github.com/caltechlibrary/newt/issues"
class="uri">https://github.com/caltechlibrary/newt/issues</a>. Just keep
in remains an <strong>experiment</strong> as of February 2024.</p>
<h2 id="documentation">Documentation</h2>
<ul>
<li><a href="user_manual.html">user manual</a></li>
<li><a href="INSTALL.html">INSTALL</a></li>
<li><a href="about.html">About</a></li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>A data pipeline is formed by taking the results from one
web service and using it as the input to another web service. It is the
web equivalent of Unix pipes. Prior art: <a
href="https://en.wikipedia.org/wiki/Yahoo!_Pipes">Yahoo! Pipes</a><a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>See <a
href="https://infrequently.org/2024/01/performance-inequality-gap-2024/"
class="uri">https://infrequently.org/2024/01/performance-inequality-gap-2024/</a>
for a nice discussion of the problem.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Shibboleth is a common single sign-on platform in
research libraries, universities and colleges.<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</section>

<footer>
<span><h1><A href="http://caltech.edu">Caltech</a></h1></span>
<span>&copy; 2023 <a href="https://www.library.caltech.edu/copyright">Caltech library</a></span>
<address>1200 E California Blvd, Mail Code 1-32, Pasadena, CA 91125-3200</address> 
<span>Phone: <a href="tel:+1-626-395-3405">(626)395-3405</a></span>
<span><a href="mailto:library@caltech.edu">Email Us</a></span>
<a class="cl-hide" href="sitemap.xml">Site Map</a>
</footer>
</body>
</html>

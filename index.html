<!DOCTYPE html>
<html>
<head>
    <title>Newt -- a new take on the webstack</title>
    <link rel="stylesheet" href="https://caltechlibrary.github.io/css/site.css">
</head>
<body>
<header>
<a href="https://library.caltech.edu"><img src="https://caltechlibrary.github.io/assets/liblogo.gif" alt="Caltech Library logo"></a>
</header>
<nav>
<ul>
	<li><a href="/">Home</a></li>
	<li><a href="./">README</a></li>
	<li><a href="user_manual.html">User Manual</a></li>
	<li><a href="LICENSE">LICENSE</a></li>
	<li><a href="INSTALL.html">INSTALL</a></li>
	<li><a href="about.html">About</a></li>
	<li><a href="https://github.com/caltechlibrary/newt">GitHub</a></li>
</ul>
</nav>

<section>
<h1 id="newt-project">Newt Project</h1>
<p>The Newt Project is an experiment in rapid web application
development for libraries, archives and museums (abbr:
<abbr title="libraries, archives and museums abbrevation">LAS</abbr>).
Newt uses a service oriented architecture forming data pipelines<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>. The pipelines compose the web
application.</p>
<p>Taking this approach minimizes the software you need to write in
favor of configuration. This is because “off the shelf” software is
available to do the heavy lifting. Example, Postgres+PostgREST gives you
an out of the box, web friendly, data management platform in the form of
a JSON API. Light weight template engines like like Newt’s Mustache
template engine can transform you JSON API output into a web page. Throw
in a full text search engine like Solr and you can check off the core
features of many LAS software systems. What is missing is the layer to
orchestrate the data flowing through a pipe.</p>
<p>The Newt Project is trying to encourage the following
characteristics.</p>
<ul>
<li>preference for “off the shelf” over writing new code</li>
<li>data modeling and management placed squarely in your database
management system</li>
<li>data sources accessed as JSON API</li>
<li>data transformation (if needed) happens in simple stateless template
engines</li>
<li>leverage code generation when appropriate</li>
</ul>
<p>The Newt Project is exploring this by providing three tools to fill
in the gaps.</p>
<ul>
<li><code>newt</code> is a stateless web service (a.k.a. micro service)
that routes a web request through a data pipeline built from other web
services</li>
<li><code>newtgen</code> is a code generator that can take a set of data
models described in YAML and generate SQL, HTML and templates based on
those models</li>
<li><code>newtmustache</code> is a simple stateless template engine
inspired by Pandoc server that supports the Mustache template
language</li>
</ul>
<p>The Newt web service and data pipeline concept is being tested
using</p>
<ul>
<li><a href="https://postgres.org">Postgres</a>, data management and
modeling</li>
<li><a href="https://postgrest.org">PostgREST</a>, a service that turns
Postgres into a JSON API</li>
<li><a href="https://solr.apache.org">Solr</a>, full text search that
provides a JSON API</li>
</ul>
<p>Newt can tie these together through YAML expressing</p>
<ul>
<li>application definition (run time information and application
metadata)</li>
<li>routes (web requests differentiated by a HTTP method, headers and
URL path)</li>
<li>models (describe the data as would be input into a web form)</li>
</ul>
<h2 id="what-type-of-applications-are-supported-by-newt">What type of
applications are supported by Newt?</h2>
<p>Most LAS applications are focused on managing and curating some sort
of metadata record. This is the primary target of Newt. This might be as
simple as a controlled vocabulary or as complex as an archival or
repository metadata record.</p>
<h2 id="motivation">Motivation</h2>
<p>Over the last several decades web applications became very complex.
This complexity is expensive in terms of reliability, enhancement, bug
fixes and software sustainability.</p>
<blockquote>
<p>A brief historic detour to set context</p>
</blockquote>
<p>Databases have been used to generate web pages since the early web.
Databases are well suited to managing data. When the web became dynamic,
databases continued to be use for data persistence. By 1993 the web as
an application platform was born<a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a> and with it a good
platform for providing useful organizational software.</p>
<p>By the mid 1990s the Open Source databases, MySQL and Postgres, were
the popular choice for building web applications. It is important to
note neither MySQL or Postgres spoke HTTP<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. To
solve this problem many people wrote software in languages like Perl,
PHP and Python that ran inside the popular Apache web server. It was a
pain to setup but once setup relatively easy to build things that relied
on databases. This led the web to explode with bespoke systems for
curating and distributing web content. By the late 1990s and the early
2000s the practice of “mashing up” sites (i.e. content reuse) became the
rage. As this increased in popularity web systems specialized further to
cater to reuse. <a
href="https://en.wikipedia.org/wiki/Yahoo!_Pipes">Yahoo Pipes</a> was a
very interesting expression of the “mashup culture”<a href="#fn4"
class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.
Yahoo Pipes inspired Newt’s data pipelines. Specialization has continued
ever since. Some of these systems have become less bespoke. Eventual
bespoke systems gave way to common use cases<a href="#fn5"
class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. A
good example of a common use case is Apache’s <a
href="https://solr.apache.org">Solr</a> search engine. Another example
was the in-house bespoke content systems gave way to systems like <a
href="https://drupal.org">Drupal</a> and <a
href="https://wordpress.org">WordPress</a>.</p>
<blockquote>
<p>fast forward to 2024, context set</p>
</blockquote>
<p>Much of the back end of web applications can largely be assemble from
off the shelf software. Middleware however remains complex. I believe
this to be a by product of inertia in software development practices and
the assumption that what is good for “Google Scale” is good for
everyone.</p>
<p>I think a radical simplification is due. Most software doesn’t need
to scale that large. Even in the research and LAS communities we don’t
routinely write software that scales as large as <a
href="https://zenodo.org/">Zenodo</a>. We don’t typically support tens
of thousands of simultaneous users. If you accept that premise then we
can focus our efforts around orchestrating off the shelf components and
put our remaining development efforts into improving the human
experience of using our software.</p>
<p>A big key to simplification is realizing that the middleware no
longer needs to be responsible for managing data models, access control
and users or data transformation. There is no requirement for being
bespoke. If you can configure the data routes and your data models the
rest can become turn key.</p>
<h2 id="off-the-shelf-deliverables">Off the shelf deliverables</h2>
<ul>
<li>(data management) Postgres combined with PostgREST gives you an out
of the box JSON API for managing data</li>
<li>(full text search) Solr gives you a powerful, friendly, JSON API for
search and discovery</li>
<li>(content transformation) Pandoc running as a web service provides a
simple but powerful template engine</li>
<li>(hosting, access control) Apache 2 or NginX when combined with a
single sign on system (e.g. Shibboleth) provides access control</li>
<li>(rich client) Web browsers now provide a rich software platform in
their own right</li>
</ul>
<h2 id="this-missing-bits">This missing bits</h2>
<p>With the only the above list can already build capable applications
that run inside the web browser. The cost, JavaScript is required to
render everything. Relying on JavaScript to assemble out content in the
web browser is a horrible idea<a href="#fn6" class="footnote-ref"
id="fnref6" role="doc-noteref"><sup>6</sup></a>. A better approach is
for the web browser to make a minimum number of requests to a single web
service and get back useful results without having to process more than
HTML and CSS.</p>
<p>Taking the better approach in the past has required the writing of
more middleware. I think we can avoid that or at least avoid complex
middleware.</p>
<p>For over a decade web frameworks developed for programming languages
like Go, Java, JavaScript, PHP, Python, and Ruby have relied on a
concept of “routes”. A “route” describes the URL path and HTTP method
used to make a web request (e.g. your web browser requesting to view an
HTML page). The mapping of a route to a function simplifies the model of
receiving and responding to HTTP requests<a href="#fn7"
class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.
The collection of routes and their functions compose the API your
browser uses to navigate through your application.</p>
<p>There is no requirement for the functions to be simple or complex. It
depends on the task they are solving. Historically before single sign-on
systems became common the function handling the request was responsible
for the whole transaction. It needed to hand access control, data
validation, data formatting, storing or retrieving data from the
database. You had to make sure the request from the public didn’t lead
to a compromise of your database’s security. This was especially true
when generate a SQL statement to interact with the database. Those
functions that did it all are complex by necessity. When we narrowly
focus a function and allow other layers of the system to handle most of
the complexity our functions can be simpler. That was the motivation and
many libraries and frameworks the proliferated in the languages used to
write middleware. What was missing was an adjustment of our assumptions.
Middleware doesn’t need to do allot of those things any more. What if a
web service specialized in being the glue? We configured the web service
and delegate away the responsibility of our middleware.</p>
<p>Here’s the new baseline I think we should consider. Web services talk
to other web services all the time. This isn’t new or exotic it has
become a traditional web development practice. Let’s take advantage of
that. What if we align access control with our front end web server or
in the database that can express itself as a JSON API? What if we could
treat the response from one web service as the input of another creating
pipe lines for web data? What if putting together pipelines was as easy
as hosting static web content? I think the answer is “yes we can” to all
these propositions.</p>
<p>Newt provides a simple web service that takes a YAML file and pairs
the requests it receives with a data pipeline. The last stage of the
pipeline executed is returned to the web browser. If there is a failure
in the pipeline then an appropriate error is returned to the requesting
web browser. Additionally Newt’s web service can provide basic data
validation by using its knowledge of the data models expressed as YAML.
Newt’s code generator uses the same YAML to generate the SQL, templates
and HTML needed to form a basic human user interface. There isn’t much
middleware left to write using this approach. If you do write middleware
it can be narrowly focused to a specific stage of your pipelines and
hopefully much simpler than the code you used to write.</p>
<h2 id="what-comes-with-the-newt-project">What comes with the Newt
Project?</h2>
<ul>
<li><a href="newt.1.html">newt</a> a <a
href="https://en.wikipedia.org/wiki/microservices">web service</a>
designed for working with other “off the shelf” web services. It
functions both as a data router and as a static file server. It is
responsible for vetting requests against the models described in the
YAML file. The same models used to generate the SQL for the database and
the templates for user with a template engine.</li>
<li><a href="newtgen.1.html">newtgen</a> is a command line program that
reads the Newt YAML file and generates SQL and templates used to build
your application. The generated SQL currently targets
Postgres+PostgREST.</li>
<li><a href="newmustache.1.html">newtmustache</a> implements a simple
lightweight template engine supporting <a
href="https://mustache.github.io/">Mustache</a> templates. Mustache
template language is support by a wide variety of programming languages.
It is provided as an alternative to using Pandoc as a template
engine.</li>
</ul>
<p>NOTE: See the <a href="user_manual.html">user manual</a> for
details</p>
<h2 id="how-is-newt-speeding-up-development">How is Newt speeding up
development?</h2>
<p>The Newt suite of tools use a common YAML file.</p>
<ol type="1">
<li><code>newtgen</code> can render SQL suitable for bootstrapping your
Postgres+PostgREST database, templates and HTML</li>
<li><code>newtmustache</code> provides a simple, stateless, Mustache
template engine</li>
<li><code>newt</code> provides data routing between other web services
that fill specific functions or roles.</li>
</ol>
<p>Your back end is constructed from “off the shelf” parts. Newt
provides the routing. It allows our customization efforts to focus on
data modeling in the database then HTML, CSS and JavaScript that will
run in your web browser.</p>
<h2 id="where-is-development-time-spent">Where is development time
spent?</h2>
<p>The developer writes YAML to generate the back end data management.
The YAML is used generate the SQL, HTML and templates needed for the
application. Other services are combined by <code>newt</code> to manage
the data pipelines which form the application’s basic functionality. The
developer can then focus on either refining the data models running in
the database or in web browser content handling.</p>
<h2
id="what-about-security-integration-with-single-sign-on-or-other-websites-or-services">What
about security, integration with single sign-on or other websites or
services?</h2>
<p>The <code>newt</code> program is a simple web service providing data
routing based on its YAML configuration. It’s a team player. In a
production setting it should be used behind a front end web server like
Apache 2 or NginX. That latter can be configured to support single
sign-on systems like Shibboleth<a href="#fn8" class="footnote-ref"
id="fnref8" role="doc-noteref"><sup>8</sup></a>. The front end web
service controls access and handles securing the connection with the web
browser. The front end web service proxies to the Newt web service. Newt
web services runs the data pipeline on localhost. The data pipelines are
off the shelf services like Postgres+PostgREST, Solr and Pandoc server.
Having a clear division of responsibilities helps in securing your web
application. Since Newt only knows how to talk to services on localhost
you can keep it contained and prevent it from being used for nefarious
actions off system. Similarly if you decide to use Newt’s template
engine, <code>newtmustache</code>, it also is restricted to
localhost.</p>
<p>Limiting Newt web service applications to localhost keeps them
simple. Only doing the minimum limits the attack surface for those who
want to do mischief. Neither <code>newt</code> or
<code>newtmustache</code> write to disk or require secrets. They only
communicate via localhost using HTTP protocol.</p>
<p>If you need to integrate a Newt application with an external service
(e.g. CrossRef, ORCID or ROR) this can be done browser side or via a
proxy mapped to localhost on your server.</p>
<h3 id="what-about-scaling">What about “scaling”?</h3>
<p><code>newt</code> is just a data router. Aside from its configuration
read at start up it doesn’t maintain state. <code>newtmustache</code>
doesn’t maintain state and the only configuration is the port number it
runs on. Both can safely run with many instances in parallel as needed
on one or more machines. The instances don’t share data or coordinate.
They start up wait for a request and providing an answer. So what does
this mean?</p>
<p>In principle a Newt based application can scale as wide as needed as
long as each element in the pipeline(s) can also scale.</p>
<p>In our example Postgres can be configured as a
<abbr title="high availability">HA</abbre> cluster. PostgREST, Pandoc
server, Newt’s mustache engine all are stateless and be run in parallel.
You can scale as large us Postgres can be scaled by adding more
instances of the stateless services.</p>
<p>While my intention with Newt is targeting the small it should scale
up to meet high volume demands.</p>
<h3 id="anatomy-of-a-newt-based-web-application">Anatomy of a Newt based
web application</h3>
<p>Newt application development is friendly to version control systems
(e.g. Git). It consists of a Newt configuration file, along with
generated SQL files, HTML templates and any static web assets you’ve
added. A typical disk layout of a Newt project could look like this-</p>
<ul>
<li><code>/</code> project folder
<ul>
<li><code>htdocs</code> this directory holds your static content needed
by your web application</li>
<li><code>*.sql</code> these are the SQL files used by your application
to define your models and behaviors in Postgres</li>
<li><code>*.tmpl</code> template files for either Pandoc or Mustache
template engines</li>
<li><code>newt.yaml</code> would hold the a Newt configuration file
(this is an example name for the configuration file, you can name it
whatever you like)</li>
<li><code>CITATION.cff</code> and <code>codemeta.json</code> for project
metadata</li>
</ul></li>
</ul>
<blockquote>
<p>Newt, a type of salamander, doesn’t seek attention. It does its own
thing. You only notice a salamander if you look carefully.</p>
</blockquote>
<h2 id="about-the-newt-source-repository">About the Newt source
repository</h2>
<p>Newt is a project of Caltech Library’s Digital Library Development
group. It is hosted on GitHub at <a
href="https://github.com/caltechlibrary/newt"
class="uri">https://github.com/caltechlibrary/newt</a>. If you have
questions, problems or concerns regarding Newt you can use GitHub issue
tracker to communicate with the development team. It is located at <a
href="https://github.com/caltechlibrary/newt/issues"
class="uri">https://github.com/caltechlibrary/newt/issues</a>.</p>
<h2 id="someday-maybe-exploration">“Someday, maybe” exploration</h2>
<ul>
<li>Integrate S3 protocol to support storing binary or large
objects</li>
</ul>
<h2 id="getting-help">Getting help</h2>
<p><strong>The Newt Project is an experiment!!</strong>. The source code
for the project is supplied “as is”. Newt is most likely broken. At a
stretch it could be considered a working prototype. You should not use
it for production systems. However if you’d like to ask a question or
have something you’d like to contribute please feel free to file a
GitHub issue, see <a
href="https://github.com/caltechlibrary/newt/issues"
class="uri">https://github.com/caltechlibrary/newt/issues</a>. Just keep
in mind it remains an <strong>experiment</strong> as of February
2024.</p>
<h2 id="documentation">Documentation</h2>
<ul>
<li><a href="user_manual.html">user manual</a></li>
<li><a href="INSTALL.html">INSTALL</a></li>
<li><a href="about.html">About</a></li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>A data pipeline is formed by taking the results from one
web service and using it as the input to another web service. It is the
web equivalent of Unix pipes. Prior art: <a
href="https://en.wikipedia.org/wiki/Yahoo!_Pipes">Yahoo! Pipes</a><a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Web applications proceeded to eat all the venerable
green screen systems they could find. Eventually they and their
corporate sponsors invented the surveillance economy we have today.
Sometimes “good ideas” have terrible consequences. Making it easier to
produce custom web applications should always be done keeping in mind
the necessity for humane and inclusive use. Newt can be both part of a
solution but also be used to exacerbate human problems.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>HTTP being the protocol the communicates with.
Essentially at the time RDBMS spoke a dialect of SQL as the unifying
language. The web of the time understood HTML and to a certain degree
XML. By 2000 people were looking for something simpler than XML to move
structured data about. <a
href="https://en.wikipedia.org/wiki/JSON">JSON</a> quickly became the
answer.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>The basic concept was to make it easy to work with “data
feeds” and combined them into a useful human friendly web pages. It even
included a visual programming language to make it friendly to the
non-programmer crowd.<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>If a use case is solved reliably enough it becomes “off
the shelf” software.<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>See <a
href="https://infrequently.org/2024/01/performance-inequality-gap-2024/"
class="uri">https://infrequently.org/2024/01/performance-inequality-gap-2024/</a>
for a nice discussion of the problem.<a href="#fnref6"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>See <a
href="https://infrequently.org/2024/01/performance-inequality-gap-2024/"
class="uri">https://infrequently.org/2024/01/performance-inequality-gap-2024/</a>
for a nice discussion of the problem.<a href="#fnref7"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Shibboleth is a common single sign-on platform in
research libraries, universities and colleges.<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</section>

<footer>
<span><h1><A href="http://caltech.edu">Caltech</a></h1></span>
<span>&copy; 2023-2024 <a href="https://www.library.caltech.edu/copyright">Caltech library</a></span>
<address>1200 E California Blvd, Mail Code 1-32, Pasadena, CA 91125-3200</address> 
<span>Phone: <a href="tel:+1-626-395-3405">(626)395-3405</a></span>
<span><a href="mailto:library@caltech.edu">Email Us</a></span>
<a class="cl-hide" href="sitemap.xml">Site Map</a>
</footer>
</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
    <title>Newt -- origin_story</title>
    <link rel="stylesheet" href="https://caltechlibrary.github.io/css/site.css">
    <base href="./">
</head>
<body>
<header>
<a href="https://library.caltech.edu"><img src="https://caltechlibrary.github.io/assets/liblogo.gif" alt="Caltech Library logo"></a>
</header>
<nav>
<ul>
	<li><a href="/">Home</a></li>
	<li><a href="./">README</a></li>
	<li><a href="user_manual.html">User Manual</a></li>
	<li><a href="LICENSE">LICENSE</a></li>
	<li><a href="INSTALL.html">INSTALL</a></li>
	<li><a href="about.html">About</a></li>
	<li><a href="search.html">Search</a></li>
	<li><a href="https://github.com/caltechlibrary/newt">GitHub</a></li>
</ul>
</nav>

<section>
<h1 id="newts-origin-story">Newt’s Origin story</h1>
<h2 id="a-small-epiphany">a small epiphany</h2>
<p>Newt came from a small epiphany. I was writing yet another flask app
and the de ja vu was intense. It got me thinking about how often I write
the same code over and over except for minor variations. Why in the
world was I doing this? That caused me to step back, take stock and see
if there was a simpler way.</p>
<p>Modern applications like Invenio RDM are created by aggregating many
web services. This is a feature of service oriented architecture also
known as micro service architecture. Invenio RDM is much cleaner than
the venerable EPrints 3 repository system but it remains highly complex.
Was this really needed? Was it an artifact of Zenodo? Zenodo is huge.
Huge numbers of concurrent interactions (bots and humans) along with a
massive amount of data and objects to manage. It is a complex system
because of its scale. At its core RDM does two things really well.
Metadata management and object storage. These are non-trivial at Zenodo
scale and RDM does a really good job at managing them. But having
migrated from EPrints to RDM recently I’ve come to question why do we
built software systems so complex? My library is unlikely to need an
application that scales as large as Zenodo. <strong>Our needs are far
more modest</strong>.</p>
<p>I reviewed the other custom metadata management applications I’ve
built, collaborated on or maintained over the last several decades. I
feel like they all could be simplified. <strong>It’s time to see how
much software we can create without writing new software.</strong></p>
<p>At Caltech Library we build allot of flask apps. Flask compared to
many frameworks is a nice balance of flexibility and simple concepts.
Looking at my applications I see that I should be writing much less. My
middleware needs to be scaled back. It should be taking on less
responsibility and be more narrowly focus. All my web applications use a
database for content storage (e.g. SQLite3, MySQL or Postgres). My code
spends allot of time modeling data, transforming it on the way to or
from the database as well as enforcing access rules. While I often use
an ORM I’m still modeling data in my application. That’s shouldn’t be
part of the middleware at all. This problem is not unique to my code or
the code we write as a group in Caltech Library. I saw the same problem
writing software at USC for a quarter century (as a student worker and
later as staff). I see the same problem when using platforms like Drupal
and WordPress.</p>
<p>How do we trim down our middleware? Looking at EPrints, RDM, and our
custom applications where at Caltech I see several areas that middleware
is covering that can be rethought or re-aligned.</p>
<ol type="1">
<li>Data modeling</li>
<li>Data validation</li>
<li>Data management</li>
<li>User management and permissions regiments</li>
<li>Data retrieval</li>
<li>Final data transformation for use by the web browser</li>
</ol>
<p>I realized that all these features often overlap with other software
in the systems we build on. For historical or evolutionary reasons we’ve
been putting those features into middleware. I believe these features
often are made redundant depending on the how we use the other systems
we build on.</p>
<p>So here’s my propositions</p>
<ul>
<li>data modeling (e.g. scheme design) should only happen in the
database</li>
<li>managing data should only happen in the database</li>
<li>database needs to be accessible via URL and return JSON content so
that SQL stays out of the middleware completely (the ORM is a symptom
not a solution)</li>
<li>user access and permissions should be pushed to the outer layer of a
web application (e.g. Apache 2 integrated with Shibboleth)</li>
<li>if the database supplies JSON responses we still need to turn that
into HTML; use a a simple, stateless template engine</li>
<li>use a single piece of software for routing data to our JSON API
through the template engine</li>
</ul>
<p>Our middleware should be focus that last stage. Everything use should
be provided by “off the shelf” components. The middleware focus is in
the final composition from the parts. It can use configuration to do
that.</p>
<p>Proposed components for testing a the simple router concept</p>
<ul>
<li>Postgres database</li>
<li>PostgREST to turns Postgres into a JSON API managed from
Postgres</li>
<li>Pandoc running as a web service (a very light weight template
engine)</li>
<li>Solr for full text search leveraging its JSON API support</li>
</ul>
<p>The router needs to be configurable such that any given URL supported
in your application can pass content between the database or search
engine and through a template engine handing back the results.</p>
<p>Flask (like many other frameworks) suggest a excellent path foreword.
Flasks lets you assign a “route” to a function. A “route” is expressed
with a path like string. It may include replaceable elements that the
function can then use to do it’s job (e.g. a record id passed in as part
of the URL’s path). If you can identify a path using a simple
description string and you pair that with a data pipeline sequence then
now have a router. The code you write is configuration for the path and
how it should proceed through a pipeline sequence.</p>
<p>Use case 1: contact the JSON API for the search engine, take the
results and run them through the template service.</p>
<p>Use case 2: contact the database via JSON API, perform an action,
take the results and run them through the template engine.</p>
<p>Use case 3: contact the search engine, get JSON results, run them
through the template engine.</p>
<p>I was able to illustrate this approach in the initial Newt prototype
I showed at SoCal Code4Lib in <a href="presentation/">July 2023</a>. The
biggest challenge wasn’t implementing the router it was inventing a YAML
syntax. My initial YAML syntax was overly complicated and ugly.</p>
<h2 id="the-2nd-prototype">The 2nd prototype</h2>
<p>A couple things fell out of that demonstration and subsequent talks
with other developer colleagues.</p>
<ul>
<li>Postgres with PostgREST providing JSON APIs is very cool (I expected
this response because it is very cool)</li>
<li>People were not interested in data routing and pipelines
(unexpected, routes seemed cool to me so I assumed it was cool to
others)</li>
</ul>
<p>This was expressed in the from of questions and comments.</p>
<ul>
<li>Do all my data modeling in SQL … ?
<ul>
<li>I don’t like SQL!</li>
<li>I don’t know enough SQL!</li>
<li>I don’t feel comfortable writing SQL!</li>
<li>Writing SQL isn’t fun!</li>
</ul></li>
<li>I don’t need a pipeline! The browser can assemble the page! …
<ul>
<li>React/Angular/(replace with your favor JS framework) means I don’t
need templates.</li>
<li>Who cares about HTML, JavaScript can deliver everything!!<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></li>
<li>But aren’t templates the old thing people used to use? Why use them
now?</li>
</ul></li>
</ul>
<blockquote>
<p>NOTE: the exclamations and summation are my editorial. Everyone I
encountered was very supportive and encouraging.</p>
</blockquote>
<p>After taking this all in and having a long think 2024 arrived. These
are my current conclusions.</p>
<ol type="1">
<li><p>When people saw Postgres combined with PostgREST and my
controversial suggestion to use SQL to model your data the discussion
shifted from frameworks to data modeling and what JSON would result.
Granted people weren’t looking forward to writing or learning more SQL.
That’s something I’ve noticed throughout most of my career. People who
like SQL tended to become database administrators or database developers
and get paid more when management by the Oracle cool-aide.</p></li>
<li><p>Shifting the discussion to where you model your data is the
important bit. The fact remains that the database engine does a much
better job of managing performance and your data then any middleware
code you’re likely to write regardless of framework or programming
language. I like writing in Go. It is a reasonably efficient language.
If the database is setup up correctly running SQL queries will beat my
processing data outside the database most days of the week. Arriving at
SQL to manage data is generally a win.</p></li>
<li><p>Data routing shouldn’t be either surprising or exciting.
<strong>Data routing should be boring.</strong> It should be boring in
the same way people take streets, sidewalks and bridges for granted.
They are just there for you to use. Structural engineers and Urban
planners may get excited about streets, sidewalks and bridges but that’s
because they help create them. The rest of us get excited when they are
not available. Data routing through web services is just like
that.</p></li>
<li><p>The SQL conundrum is a problem. While database engines like
Postgres can support writing functions and procedures in non-SQL
languages you still need to know and type at least some SQL. I think in
part that is why we’re still in the complex middleware quagmire.
Avoiding messing about with SQL is a feature. On the plus side if your
database hands you JSON and you can hand back JSON your middleware
doesn’t need to know about SQL and you can avoid the cognitive overhead
embedding SQL into your non-SQL program.</p></li>
</ol>
<h2 id="addressing-the-sql-conundrum">Addressing the SQL conundrum</h2>
<blockquote>
<p>SQL is a problem because embedding SQL causes a cognitive shift.<a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a> SQL is a problem because it is
significantly different from general purpose programming languages</p>
</blockquote>
<p>In most computer languages we are telling the computer how to do
something. This is true even with object oriented languages, e.g. take
this object and apply it’s method. SQL takes a different approach. The
SQL engine is going to do the heavy lifting. Instead we use SQL to
express the result we want. In other words the “what” question versus
the “how” instructions. When we embed SQL in a procedural or object
oriented language we force these two together in close proximity. Newt’s
approach to take advantage of distance. By using SQL code generation we
don’t focus on the what at the same time we’re focusing on the how.</p>
<p>I feel comfortable with SQL. I’ve learned it informally<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.
I’ve personally found it challenging when embedding in a general purpose
language like Python. This is true even when I’ve used an ORM. It’s a
constant tug of war between thinking about Python (the how) then
thinking about the SQL (the what I asked for). Typically I’ve wound up
assembling the SQL statements and running them directly in the database
to gain insight into unexpected behavior. If the SQL is conditionally
constructed then it become harder to figure out exactly when was sent to
the SQL engine.</p>
<p>The result of that experience has convinced me that keeping the SQL
separate as SQL is helpful. I can work directly with the database and
understand what I’m asking for (e.g. INSERT, SELECT, UPDATE, DELETE).
When you do need to embed it using an SQL view can often simplify a
complex SQL statement lowering the cognitive overhead.</p>
<p>Two general approaches appear promising to me. Separate your SQL out
and don’t embedding it. Use a combo like Postgres plus PostgREST to get
a JSON API web service. Your middleware doesn’t need to include any SQL
at all then. It just calls URLs can procedurally processes results. If
you can generate the SQL you need in the database because you know you
will need to support CRUD-L then that saves time writing SQL to do
that.</p>
<p>I’m not advocating avoiding learning SQL. But I am advocating
learning as much as you need when you need it. I am also advocating your
middleware should be ignorant completely of SQL. Working with human
readable generated SQL can afford you the opportunity to learn SQL
incrementally. It gives you the opportunity to learn to trust the
database<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a> as a partner rather than simply as a
place to store things.</p>
<p>I have come to think about SQL’s domain specific languages as service
descriptions.</p>
<dl>
<dt>DDL, data definition language</dt>
<dd>
This language describes the data structure of the objects you’re going
to work with, e.g. table rows and columns. CREATE and ALTER are part of
SQL DDL.
</dd>
<dt>DQL, data query language</dt>
<dd>
This is the language you used to retrieve or list objects you stored,
e.g. rows from a table. SELECT and WITH are part of the SQL DQL. You’ll
spend allot of time using this one when you write your own SQL.
</dd>
<dt>DML, data modification language</dt>
<dd>
This is the language you used to create, update and delete objects.
e.g. modify rows or columns in a table. INSERT, UPDATE and DELETE are
part of the SQL DML.
</dd>
</dl>
<p>Thinking of these as services lets me step back and simplify my
interactions with our data. The nice thing about this approach is that
orchestrating services can be thought of completely procedurally. This
how Newt approaches SQL code generation. It can express the services it
needs (e.g. create a record, read back some records, update or delete
records) because it knows about the model being used.
<code>newtgen</code> renders models as human readable SQL files
(complete with comments). This gives us a change to both test the SQL
but also to pick learn it as we explore the generated code.</p>
<p>If your application only requires the basic CRUD-L<a href="#fn5"
class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>
then you might be able to skip the SQL completely.</p>
<p>Taking SQL code generation approach like an ORM let’s you postpone
thinking about SQL while you’re coding in your general purpose language.
Code generation, unlike an ORM, let’s you avoid the constant cognitive
shifts. When you’re ready to deal with SQL you focus your time in the
database<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a>. Less frequent cognitive shifts
makes the task more pleasant.</p>
<p>It was stumbling on the Postgres+PostgREST combo that remembered data
pipelines. Newt became obvious when I realized that the setup of
Postgres+PostgREST could be calculated from a configuration file. I
quickly realized that the combo of Postgres+PostgREST meant any JSON
data source code be a first stage in a pipeline. Of course other SQL
engines can perform a similar role<a href="#fn7" class="footnote-ref"
id="fnref7" role="doc-noteref"><sup>7</sup></a> but the
Postgres+PostgREST really fit the bill nicely for the systems I’m
working with.</p>
<h2 id="a-recent-insight">A recent insight</h2>
<p>A colleague of mine recently demonstrated an innovative use of GitHub
issue templates to trigger GitHub workflows for our library’s staff.
What impressed me about the demonstration (besides my colleague’s cool
application) was the YAML used to express what an issue was. After some
thinking I realized my original YAML for Newt could be supplanted by
GitHub YAML issue template syntax. This would simplify documenting and
teaching Newt configuration.</p>
<p>GitHub YAML issue templates syntax (abbr: GHYTS) describes the data
model used by GitHub issues. It does this by describing the elements
you’d expected in an HTML web form. My realization was I could cut the
weight of my original YAML syntax considerable by letting a description
of HTML input elements infer a mapping to Postgres SQL types. E.g. a
plain <code>input</code> element is a <code>string</code> -&gt;
<code>varchar</code>. A <code>textarea</code> maps to a
<code>text</code> data type. An HTML5 data element expressed
<code>input[type=date]</code> maps to a SQL date type. This isn’t
accidental. HTML web forms were designed to make it easier to get data
into a database. If a table row is analogous to an object and an input
element is analogous to a column I have a clear mapping for generating
SQL without resorting to the developer knowing SQL data types. If we
take an additional step forward and require JSON column support in our
SQL database (MySQL, Postgres and SQLite have for the last decade) and
we require the form to use JSON encoding then even elements like
checkbox or select lists become easily to send over the wire and can
have simpler expressions in SQL.</p>
<p>By extrapolation web components can be expressed as JSON objects.
This allows Newt to be enriched with data types specific to libraries,
archives and museums. A corollary is the objects stored as a JSON column
can be expressed as web components. Write a web component take effort.
The duplication of effort can be reduced if Newt to includes the common
cases used in libraries, archives and museums.</p>
<h2 id="whats-next">What’s next?</h2>
<p>The second prototype for Newt is focusing and developing an improved
YAML syntax. The plan is to used <a
href="https://citation-file-format.github.io/">CITATION.cff</a> for
application metadata while using GHYTS for models and GHYTS input types
to describe route variables. These changes also come with renewed focus
on code generation targeting SQL for Postgres+PostgREST, Mustache
templates for <code>newtmustache</code> web service and HTML elements
for web forms and display.</p>
<p>The simpler YAML reusing existing YAML domain syntax along with code
generation should ease or remove burden of writing middleware.</p>
<p>A future prototype may include web components used to represent
common types of data, e.g. author lists, common identifiers (e.g. DOI,
arXiv, ORCID, ROR). This could simply the templates generated by Newt
while also encouraging an ecosystem of share web objects among the LAM
community.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Example: SquareSpace and Wix deliver web pages as
JavaScript. I think this is to hide what they are really selling.<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The price of that shift is similar to when you inline
CSS or JavaScript in HTML.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>SQL is built up from smaller domain specific languages.
I’ve only learned each when I needed it.<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>I would go so far as saying attempting to learn a SQL
dialect all at once is a bad idea.<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Data operations often fall under the acronym CRUD-L.
Create, Read, Upload, Delete and List. That’s a good thing. With a the
knowledge of a data model you can calculate the SQL needed for those
operations. No AI needed :wink:.<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Loading a file of SQL commands, say “myfile.sql”
targeting “mydatabase”, is trivial with <code>psql</code>. Example:
<code>psql mydatabase &lt;myfile.sql</code>.<a href="#fnref6"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>MySQL can be coupled with MySQL REST Service (MRS) to
achieve a similar results a Postgres+PostgREST<a href="#fnref7"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</section>

<footer>
<span><h1><A href="http://caltech.edu">Caltech</a></h1></span>
<span>&copy; 2023-2024 <a href="https://www.library.caltech.edu/copyright">Caltech library</a></span>
<address>1200 E California Blvd, Mail Code 1-32, Pasadena, CA 91125-3200</address> 
<span>Phone: <a href="tel:+1-626-395-3405">(626)395-3405</a></span>
<span><a href="mailto:library@caltech.edu">Email Us</a></span>
<a class="cl-hide" href="sitemap.xml">Site Map</a>
</footer>
</body>
</html>
